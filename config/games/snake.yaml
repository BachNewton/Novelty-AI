# Snake Game Configuration
# See docs/games/snake/EXPERIMENTS.md for rationale behind these values

# Game Settings
game:
  grid_width: 20
  grid_height: 20

# Training Hyperparameters
training:
  episodes: 5000
  batch_size: 64
  learning_rate: 0.001
  gamma: 0.99  # Discount factor

  # Epsilon (exploration) - slower decay for enhanced state features
  epsilon_start: 1.0
  epsilon_min: 0.02
  epsilon_decay: 0.998

  # Experience replay
  buffer_size: 100000
  target_update_freq: 100

  # Double DQN reduces Q-value overestimation
  use_double_dqn: true

  # Checkpointing
  save_interval: 100  # Save model every N episodes
  checkpoint_dir: "models/snake"

# Reward shaping (see EXPERIMENTS.md for why most are disabled)
rewards:
  food: 10.0
  death: -10.0
  step_penalty: -0.01        # Small penalty encourages efficiency
  approach_food: 0.0         # Disabled
  retreat_food: 0.0          # Disabled
  length_bonus_factor: 0.0   # Disabled

# Replay Settings
replay:
  enabled: true
  save_dir: "replays/snake"
  playback_fps: 10  # Slower than training for watchability
  max_replays: 10   # Keep only the best N replays
